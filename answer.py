from langchain_ollama import ChatOllama
from langchain_community.vectorstores import PGVector
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA

# === åŸºæœ¬é…ç½® ===
CONNECTION_STRING = "postgresql+psycopg2://admin:admin123@localhost:5432/vectordb"
COLLECTION_NAME = "products"

# === åŠ è½½æœ¬åœ° embedding æ¨¡å‹ ===
embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-large-en-v1.5")

# === ä»å·²æœ‰é›†åˆåŠ è½½ PGVector ===
vectorstore = PGVector.from_existing_index(
    embedding=embeddings,
    collection_name=COLLECTION_NAME,
    connection_string=CONNECTION_STRING,
)

# === æ„å»ºæ£€ç´¢å™¨ ===
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# === ä½¿ç”¨æœ¬åœ° gpt-oss:20b ===
llm = ChatOllama(model="gpt-oss:20b", temperature=0.3)

# === æ„å»º RAG é—®ç­”é“¾ ===
qa = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=True
)

# === ç¤ºä¾‹æŸ¥è¯¢ ===
query = "å“ªæ¬¾ iPhone 17 æœ€ä¾¿å®œï¼Ÿ"
result = qa.invoke(query)

print("ğŸ” é—®é¢˜:", query)
print("ğŸ’¡ å›ç­”:", result["result"])
print("ğŸ“‚ æ¥æº:")
for doc in result["source_documents"]:
    print("-", doc.metadata["original_name"])